{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DP_BERT(final).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"python3","language":"python","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d09550c1c6724988a7855f5ca0669dd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6744e462b31d496f868f7b124605c27d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6eafe7356a3e4b6b88b146322d642f12","IPY_MODEL_7be958be02cf4d4493642345a9f593d4","IPY_MODEL_816644b1c25642ac80e6810b46bb51f2"]}},"6744e462b31d496f868f7b124605c27d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6eafe7356a3e4b6b88b146322d642f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4c54ebb1a5f94361ba8501ab9763b55d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f003c9f8a55a465597018b377952ce06"}},"7be958be02cf4d4493642345a9f593d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3f958c5e2d934c33a2b254e7b7274a7b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8ed274aa57841ff8df150b2e143b1a1"}},"816644b1c25642ac80e6810b46bb51f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a75abff9cc34471bcec54efe01e85c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 18.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_becd5cb728974aab94557502d0b21432"}},"4c54ebb1a5f94361ba8501ab9763b55d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f003c9f8a55a465597018b377952ce06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f958c5e2d934c33a2b254e7b7274a7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8ed274aa57841ff8df150b2e143b1a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a75abff9cc34471bcec54efe01e85c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"becd5cb728974aab94557502d0b21432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57996801726d4b89b727ee273472400e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_11a299eaf47740f5af7da91b9d4d8e11","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_774b4c14d24b47f1a6aa1c995698db8a","IPY_MODEL_ddd0cf6d41444a5ca9f2ff92f1550049","IPY_MODEL_e5149479196f4a4fb5498a5ec7219691"]}},"11a299eaf47740f5af7da91b9d4d8e11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"774b4c14d24b47f1a6aa1c995698db8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d54fdfe5ab6e4e5bb2e5a505e84c539b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69b6d3023d554c218869ff747f4eb89a"}},"ddd0cf6d41444a5ca9f2ff92f1550049":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74e9c6b59539478c80da19897cca68ac","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_697749d30b324a978c50181b134f23c4"}},"e5149479196f4a4fb5498a5ec7219691":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_238285f86c3e45cbbfed23ed2d93a273","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 2.47MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75e4ffaaa054415e96a2561cf4c5c88b"}},"d54fdfe5ab6e4e5bb2e5a505e84c539b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69b6d3023d554c218869ff747f4eb89a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74e9c6b59539478c80da19897cca68ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"697749d30b324a978c50181b134f23c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"238285f86c3e45cbbfed23ed2d93a273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"75e4ffaaa054415e96a2561cf4c5c88b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3772cce6aa7e4cfeb0e3b6cf8de9a493":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e298ff9767be4136b3b61bfb9f074a8e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_daf351e6a6ce421582a3cba728fca686","IPY_MODEL_49d9a6f32fba47bab92780395cd9399d","IPY_MODEL_b0f87ff0b00b486f87807538ddb4a574"]}},"e298ff9767be4136b3b61bfb9f074a8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"daf351e6a6ce421582a3cba728fca686":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8e3b2d897ed0491eb9f8aeecc62508cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63cc3e05adf940348c79df970d2ee20c"}},"49d9a6f32fba47bab92780395cd9399d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c549fe516ca1495491b920c07bc02736","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_707d2be42e0048349495b3680f3e20b4"}},"b0f87ff0b00b486f87807538ddb4a574":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8dbad1c1b2c4c829bf12d991f7f9451","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 1.09kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_992422a4bc15425ebd8d756973732125"}},"8e3b2d897ed0491eb9f8aeecc62508cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63cc3e05adf940348c79df970d2ee20c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c549fe516ca1495491b920c07bc02736":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"707d2be42e0048349495b3680f3e20b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8dbad1c1b2c4c829bf12d991f7f9451":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"992422a4bc15425ebd8d756973732125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a85c64d9fa2a4c65a738b2a9ac505782":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aac5d36f7dd74c9880354eed1b94fab5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_95a3660936ff4730b0ecb381e1e3a67e","IPY_MODEL_79e0dedf21a44ae8927fed82b68b1b5f","IPY_MODEL_058a21f861c44fc0bab7324a52825e06"]}},"aac5d36f7dd74c9880354eed1b94fab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95a3660936ff4730b0ecb381e1e3a67e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03777192c9ee4078bcc2761d31027480","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f3a0df436b747f9b47676a6a6f7d9fb"}},"79e0dedf21a44ae8927fed82b68b1b5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5a8e4778bd844f92ba11befe41055a58","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfd304d881554c9e9b86b98cfbf1e0c0"}},"058a21f861c44fc0bab7324a52825e06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_97fbd3fedd804eccbed718dad4a18716","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426k/426k [00:00&lt;00:00, 4.36MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e9486c691364545977c4d92c0bc5271"}},"03777192c9ee4078bcc2761d31027480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f3a0df436b747f9b47676a6a6f7d9fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a8e4778bd844f92ba11befe41055a58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cfd304d881554c9e9b86b98cfbf1e0c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97fbd3fedd804eccbed718dad4a18716":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0e9486c691364545977c4d92c0bc5271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"640cb8701f284db6865d5fe0691722e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a531710f865748d8843b158b5559eeed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f00aed362fce42c599f2c789938d2542","IPY_MODEL_42bec5fe217a40bd95b3f01c2d823d01","IPY_MODEL_40d8582095044b07a10bca5d5d60a836"]}},"a531710f865748d8843b158b5559eeed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f00aed362fce42c599f2c789938d2542":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e18d3902917a4ca0b370a9634c982573","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fab1a9ba42c341609051242e7236c317"}},"42bec5fe217a40bd95b3f01c2d823d01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9b8525c457244dc2911e1eb9d765eb89","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cdf7f81f6c894f87979cc090b3e7604b"}},"40d8582095044b07a10bca5d5d60a836":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5bd7b8f5601741dba8f5ddc7afd084c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:08&lt;00:00, 44.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d75c83a155ab41db958c2a8a4894544c"}},"e18d3902917a4ca0b370a9634c982573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fab1a9ba42c341609051242e7236c317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b8525c457244dc2911e1eb9d765eb89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cdf7f81f6c894f87979cc090b3e7604b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bd7b8f5601741dba8f5ddc7afd084c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d75c83a155ab41db958c2a8a4894544c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2747d4def4044b2ab7986aa6374323ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2090cb5c8d8b4ee9932adb98c2b4b05e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b76d2e01514b461a87472249cf637b81","IPY_MODEL_153dd19ba7cf4fe084baf5f96a254a16","IPY_MODEL_72246a2ab738465ebf18555e1f3a70cb"]}},"2090cb5c8d8b4ee9932adb98c2b4b05e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b76d2e01514b461a87472249cf637b81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_078bb7ff6e7c475f869136b589f91e62","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 98%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a6f41073e6746d0808eaf3ea5f60779"}},"153dd19ba7cf4fe084baf5f96a254a16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4500279cf0d047aeac58fe3bfd6bffa9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":3824,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3755,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73503cdc8bd84cb59a47004d7a716666"}},"72246a2ab738465ebf18555e1f3a70cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c9af4e0531b42259b4b4f731bf76b8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3755/3824 [09:46&lt;00:02, 27.19it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26057ae8de674b07b1ae23c697992c6c"}},"078bb7ff6e7c475f869136b589f91e62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9a6f41073e6746d0808eaf3ea5f60779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4500279cf0d047aeac58fe3bfd6bffa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73503cdc8bd84cb59a47004d7a716666":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c9af4e0531b42259b4b4f731bf76b8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"26057ae8de674b07b1ae23c697992c6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b4020bd80364dd99dd1bf5cd1a0e334":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b67c1a3bc2142609acaa6f5753c14fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_569ef315ba9b42b6903b0807c6b94cd1","IPY_MODEL_02940e86a6414a3c9ae5df2d1a971d99","IPY_MODEL_3f2ac57490fe4841a4a5bb514572da70"]}},"3b67c1a3bc2142609acaa6f5753c14fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"569ef315ba9b42b6903b0807c6b94cd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_463b46e639a340fb891399d30f49eea2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 98%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df279523355147cc817b272e1a2475c7"}},"02940e86a6414a3c9ae5df2d1a971d99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0adb8f5ec45845cbaa695c547fedb92f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":3824,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3755,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab643e6a091f433dbf480f15042876b6"}},"3f2ac57490fe4841a4a5bb514572da70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da628b5310ad40bfad41cc87a0dd3fff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3755/3824 [09:50&lt;00:02, 26.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_502ada72250a4914934b22f23421aa52"}},"463b46e639a340fb891399d30f49eea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df279523355147cc817b272e1a2475c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0adb8f5ec45845cbaa695c547fedb92f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab643e6a091f433dbf480f15042876b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da628b5310ad40bfad41cc87a0dd3fff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"502ada72250a4914934b22f23421aa52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"662696c77e8349dc9f8019f28feed0a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bca5dcec3cf64802b9e73eeeb9edd37f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91a310a37b164b54900590995eae75b3","IPY_MODEL_6eaabe21ccaf4ff7bb92d63159253ebe","IPY_MODEL_3567853897ca409397045a7b57cca4ed"]}},"bca5dcec3cf64802b9e73eeeb9edd37f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91a310a37b164b54900590995eae75b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75c44c2380884115ae1a03059438b32b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 98%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_844ac4256a0849d0b1c8a60ca9f5cb5e"}},"6eaabe21ccaf4ff7bb92d63159253ebe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b1d31b798c3e4b78911d7a69de263c8a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":3824,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3755,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_459dae1962c64d989df87f3f310770a3"}},"3567853897ca409397045a7b57cca4ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e3b8a37904e449429a094da4b8d592fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3755/3824 [09:53&lt;00:02, 26.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b0b8e812bd444959a8eceb0140428a8"}},"75c44c2380884115ae1a03059438b32b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"844ac4256a0849d0b1c8a60ca9f5cb5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1d31b798c3e4b78911d7a69de263c8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"459dae1962c64d989df87f3f310770a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3b8a37904e449429a094da4b8d592fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7b0b8e812bd444959a8eceb0140428a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AV0MK_GWsn2O"},"source":["# Building text classifier with Differential Privacy"]},{"cell_type":"markdown","metadata":{"id":"wVu4HMVesn2V"},"source":["In this tutorial we will train a text classifier with Differential Privacy by taking a model pre-trained on public text data and fine-tuning it for a different task.\n","\n","When training a model with differential privacy, we almost always face a trade-off between model size and accuracy on the task. The exact details depend on the problem, but a rule of thumb is that the fewer parameters the model has, the easier it is to get a good performance with DP.\n","\n","Most state-of-the-art NLP models are quite deep and large (e.g. [BERT-base](https://github.com/google-research/bert) has over 100M parameters), which makes task of training text model on a private datasets rather challenging.\n","\n","One way of addressing this problem is to divide the training process into two stages. First, we will pre-train the model on a public dataset, exposing the model to generic text data. Assuming that the generic text data is public, we will not be using differential privacy at this step. Then, we freeze most of the layers, leaving only a few upper layers to be trained on the private dataset using DP-SGD. This way we can get the best of both worlds - we have a deep and powerful text understanding model, while only training a small number of parameters with differentially private algorithm.\n","\n","In this tutorial we will take the pre-trained [BERT-base](https://github.com/google-research/bert) model and fine-tune it to recognize textual entailment on the [SNLI](https://nlp.stanford.edu/projects/snli/) dataset."]},{"cell_type":"markdown","metadata":{"id":"r38Umb4Tsn2W"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":77},"id":"eqpKXZEC2HMK","executionInfo":{"status":"ok","timestamp":1638734579336,"user_tz":420,"elapsed":34450,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"7e0da558-2b14-4405-dccf-ccc75ee08f05"},"source":["from google.colab import files\n","CS_file = files.upload()"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-d49a6379-0b0f-42ba-933a-340dff994885\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d49a6379-0b0f-42ba-933a-340dff994885\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving CovidSentimentData.csv to CovidSentimentData.csv\n"]}]},{"cell_type":"code","metadata":{"id":"sJ_7cfND2-tf","executionInfo":{"status":"ok","timestamp":1638734582346,"user_tz":420,"elapsed":176,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["import io\n","import pandas as pd\n","\n","data = pd.read_csv(io.BytesIO(CS_file['CovidSentimentData.csv']))"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CecGEYys3DD4","executionInfo":{"status":"ok","timestamp":1638734593327,"user_tz":420,"elapsed":456,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","df_train, df_test = train_test_split(data, random_state=42, test_size=0.2)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCtvOwBgsn2g"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"iyp7UwoHsn2h"},"source":["BERT (Bidirectional Encoder Representations from Transformers) is state of the art approach to various NLP tasks. It uses a Transformer architecture and relies heavily on the concept of pre-training. \n","\n","We'll use a pre-trained BERT-base model, provided in huggingface [transformers](https://github.com/huggingface/transformers) repo.\n","It gives us a pytorch implementation for the classic BERT architecture, as well as a tokenizer and weights pre-trained on a public English corpus (Wikipedia).\n","\n","Please follow these [installation instrucitons](https://github.com/huggingface/transformers#installation) before proceeding."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAIfvnsws6H4","executionInfo":{"status":"ok","timestamp":1638734948815,"user_tz":420,"elapsed":7171,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"c81eeb10-0de0-4a3d-999f-be4438b97027"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 70.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 627 kB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 81.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 61.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["d09550c1c6724988a7855f5ca0669dd8","6744e462b31d496f868f7b124605c27d","6eafe7356a3e4b6b88b146322d642f12","7be958be02cf4d4493642345a9f593d4","816644b1c25642ac80e6810b46bb51f2","4c54ebb1a5f94361ba8501ab9763b55d","f003c9f8a55a465597018b377952ce06","3f958c5e2d934c33a2b254e7b7274a7b","b8ed274aa57841ff8df150b2e143b1a1","7a75abff9cc34471bcec54efe01e85c4","becd5cb728974aab94557502d0b21432","57996801726d4b89b727ee273472400e","11a299eaf47740f5af7da91b9d4d8e11","774b4c14d24b47f1a6aa1c995698db8a","ddd0cf6d41444a5ca9f2ff92f1550049","e5149479196f4a4fb5498a5ec7219691","d54fdfe5ab6e4e5bb2e5a505e84c539b","69b6d3023d554c218869ff747f4eb89a","74e9c6b59539478c80da19897cca68ac","697749d30b324a978c50181b134f23c4","238285f86c3e45cbbfed23ed2d93a273","75e4ffaaa054415e96a2561cf4c5c88b","3772cce6aa7e4cfeb0e3b6cf8de9a493","e298ff9767be4136b3b61bfb9f074a8e","daf351e6a6ce421582a3cba728fca686","49d9a6f32fba47bab92780395cd9399d","b0f87ff0b00b486f87807538ddb4a574","8e3b2d897ed0491eb9f8aeecc62508cb","63cc3e05adf940348c79df970d2ee20c","c549fe516ca1495491b920c07bc02736","707d2be42e0048349495b3680f3e20b4","d8dbad1c1b2c4c829bf12d991f7f9451","992422a4bc15425ebd8d756973732125","a85c64d9fa2a4c65a738b2a9ac505782","aac5d36f7dd74c9880354eed1b94fab5","95a3660936ff4730b0ecb381e1e3a67e","79e0dedf21a44ae8927fed82b68b1b5f","058a21f861c44fc0bab7324a52825e06","03777192c9ee4078bcc2761d31027480","2f3a0df436b747f9b47676a6a6f7d9fb","5a8e4778bd844f92ba11befe41055a58","cfd304d881554c9e9b86b98cfbf1e0c0","97fbd3fedd804eccbed718dad4a18716","0e9486c691364545977c4d92c0bc5271","640cb8701f284db6865d5fe0691722e0","a531710f865748d8843b158b5559eeed","f00aed362fce42c599f2c789938d2542","42bec5fe217a40bd95b3f01c2d823d01","40d8582095044b07a10bca5d5d60a836","e18d3902917a4ca0b370a9634c982573","fab1a9ba42c341609051242e7236c317","9b8525c457244dc2911e1eb9d765eb89","cdf7f81f6c894f87979cc090b3e7604b","5bd7b8f5601741dba8f5ddc7afd084c0","d75c83a155ab41db958c2a8a4894544c"]},"id":"hm0usUDzsn2h","executionInfo":{"status":"ok","timestamp":1638734970373,"user_tz":420,"elapsed":19953,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"8a6f54ed-3cf6-439d-f6c4-b04618569637"},"source":["from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n","\n","model_name = \"bert-base-cased\"\n","\n","config = BertConfig.from_pretrained(\n","    model_name,\n","    num_labels=2,\n",")\n","tokenizer = BertTokenizer.from_pretrained(\n","    \"bert-base-cased\",\n","    do_lower_case=True,\n",")\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-cased\",\n","    config=config,\n",")"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d09550c1c6724988a7855f5ca0669dd8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57996801726d4b89b727ee273472400e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3772cce6aa7e4cfeb0e3b6cf8de9a493","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a85c64d9fa2a4c65a738b2a9ac505782","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"640cb8701f284db6865d5fe0691722e0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","metadata":{"id":"oeVVCeoMsn2i"},"source":["The model has the following structure. It uses a combination of word, positional and token *embeddings* to create a sequence representation, then passes the data through 12 *transformer encoders* and finally uses a *linear classifier* to produce the final label.\n","As the model is already pre-trained and we only plan to fine-tune few upper layers, we want to freeze all layers, except for the last encoder and above (`BertPooler` and `Classifier`)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbCfQoJjsn2j","executionInfo":{"status":"ok","timestamp":1638734975612,"user_tz":420,"elapsed":205,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"2cf1a609-8a43-4d60-9eef-759c31f1a730"},"source":["trainable_layers = [model.bert.encoder.layer[-1], model.bert.pooler, model.classifier]\n","total_params = 0\n","trainable_params = 0\n","\n","for p in model.parameters():\n","        p.requires_grad = False\n","        total_params += p.numel()\n","\n","for layer in trainable_layers:\n","    for p in layer.parameters():\n","        p.requires_grad = True\n","        trainable_params += p.numel()\n","\n","print(f\"Total parameters count: {total_params}\") # ~108M\n","print(f\"Trainable parameters count: {trainable_params}\") # ~7M"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters count: 108311810\n","Trainable parameters count: 7680002\n"]}]},{"cell_type":"markdown","metadata":{"id":"84dS1unlsn2j"},"source":["Thus, by using pre-trained model we reduce the number of trainable params from over 100 millions to just above 7.5 millions. This will help both performance and convergence with added noise."]},{"cell_type":"markdown","metadata":{"id":"3ByP3bLVsn2l"},"source":["## Prepare the data"]},{"cell_type":"markdown","metadata":{"id":"GsTirsY8sn2l"},"source":["Before we begin training, we need to preprocess the data and convert it to the format our model expects. \n","\n","(Note: it'll take 5-10 minutes to run on a laptop)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IqQn0kt1RcQ","executionInfo":{"status":"ok","timestamp":1638735016658,"user_tz":420,"elapsed":20242,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"f52e077b-0962-4a83-e498-50a763917f25"},"source":["LABEL_LIST = [0,1]\n","MAX_SEQ_LENGHT = 128\n","\n","import torch\n","import transformers\n","from torch.utils.data import TensorDataset\n","from transformers.data.processors.utils import InputExample\n","from transformers.data.processors.glue import glue_convert_examples_to_features\n","\n","\n","def _create_examples(df, set_type):\n","    \"\"\" Convert raw dataframe to a list of InputExample. Filter malformed examples\n","    \"\"\"\n","    examples = []\n","    for index, row in df.iterrows():\n","        if row['target'] not in LABEL_LIST:\n","            continue\n","        if not isinstance(row['Tweet'], str):\n","            continue\n","            \n","        guid = f\"{index}-{set_type}\"\n","        examples.append(\n","            InputExample(guid=guid, text_a=row['Tweet'], label=row['target']))\n","    return examples\n","\n","def _df_to_features(df, set_type):\n","    \"\"\" Pre-process text. This method will:\n","    1) tokenize inputs\n","    2) cut or pad each sequence to MAX_SEQ_LENGHT\n","    3) convert tokens into ids\n","    \n","    The output will contain:\n","    `input_ids` - padded token ids sequence\n","    `attention mask` - mask indicating padded tokens\n","    `token_type_ids` - mask indicating the split between premise and hypothesis\n","    `label` - label\n","    \"\"\"\n","    examples = _create_examples(df, set_type)\n","    \n","    #backward compatibility with older transformers versions\n","    legacy_kwards = {}\n","    from packaging import version\n","    if version.parse(transformers.__version__) < version.parse(\"2.9.0\"):\n","        legacy_kwards = {\n","            \"pad_on_left\": False,\n","            \"pad_token\": tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n","            \"pad_token_segment_id\": 0,\n","        }\n","    \n","    return glue_convert_examples_to_features(\n","        examples=examples,\n","        tokenizer=tokenizer,\n","        label_list=LABEL_LIST,\n","        max_length=MAX_SEQ_LENGHT,\n","        output_mode=\"classification\",\n","        **legacy_kwards,\n","    )\n","\n","def _features_to_dataset(features):\n","    \"\"\" Convert features from `_df_to_features` into a single dataset\n","    \"\"\"\n","    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    all_attention_mask = torch.tensor(\n","        [f.attention_mask for f in features], dtype=torch.long\n","    )\n","    all_token_type_ids = torch.tensor(\n","        [f.token_type_ids for f in features], dtype=torch.long\n","    )\n","    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n","    dataset = TensorDataset(\n","        all_input_ids, all_attention_mask, all_token_type_ids, all_labels\n","    )\n","\n","    return dataset\n","\n","train_features = _df_to_features(df_train, \"train\")\n","test_features = _df_to_features(df_test, \"test\")\n","\n","train_dataset = _features_to_dataset(train_features)\n","test_dataset = _features_to_dataset(test_features)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"]}]},{"cell_type":"markdown","metadata":{"id":"0-yAHmq0sn2m"},"source":["## Choosing batch size\n","\n","Let's talk about batch sizes for a bit.\n","\n","In addition to all the considerations you normally take into account when choosing batch size, training model with DP adds another one - privacy cost. \n","\n","Because of the threat model we assume and the way we add noise to the gradients, larger batch sizes (to a certain extent) generally help convergence. We add the same amount of noise to each gradient update (scaled to the norm of one sample in the batch) regardless of the batch size. What this means is that as the batch size increases, the relative amount of noise added decreases. while preserving the same epsilon guarantee. \n","\n","You should, however, keep in mind that increasing batch size has its price in terms of epsilon, which grows at `O(sqrt(batch_size))` as we train (therefore larger batches make it grow faster). The good strategy here is to experiment with multiple combinations of `batch_size` and `noise_multiplier` to find the one that provides best possible quality at acceptable privacy guarantee.\n","\n","There's another side to this - memory. Opacus computes and stores *per sample* gradients, so for every normal gradient, Opacus will store `n=batch_size` per-sample gradients on each step, thus increasing the memory footprint by at least `O(batch_size)`. In reality, however, the peak memory requirement is `O(batch_size^2)` compared to non-private model. This is because some intermediate steps in per sample gradient computation involve operations on two matrices, each with batch_size as one of the dimensions.\n","\n","The good news is, we can pick the most appropriate batch size, regardless of memory constrains. Opacus has built-in support for *virtual* batches. Using it we can separate physical steps (gradient computation) and logical steps (noise addition and parameter updates): use larger batches for training, while keeping memory footprint low. Below we will specify two constants:\n","\n","- `BATCH_SIZE` defines the maximum batch size we can afford from a memory standpoint, and only affects computation speed\n","- `VIRTUAL_BATCH_SIZE`, on the other hand, is equivalent to normal batch_size in the non-private setting, and will affect convergence and privacy guarantee.\n","\n"]},{"cell_type":"code","metadata":{"id":"bsKJSedtsn2m","executionInfo":{"status":"ok","timestamp":1638735016660,"user_tz":420,"elapsed":9,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["BATCH_SIZE = 4\n","VIRTUAL_BATCH_SIZE = 32\n","assert VIRTUAL_BATCH_SIZE % BATCH_SIZE == 0 # VIRTUAL_BATCH_SIZE should be divisible by BATCH_SIZE\n","N_ACCUMULATION_STEPS = int(VIRTUAL_BATCH_SIZE / BATCH_SIZE)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMOjEEWk69UP","executionInfo":{"status":"ok","timestamp":1638735073057,"user_tz":420,"elapsed":3336,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"83b67365-abf7-4f74-ea78-876742a0c9d2"},"source":["!pip install opacus==0.15.0"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opacus==0.15.0\n","  Downloading opacus-0.15.0-py3-none-any.whl (125 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus==0.15.0) (1.4.1)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus==0.15.0) (1.19.5)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from opacus==0.15.0) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->opacus==0.15.0) (3.10.0.2)\n","Installing collected packages: opacus\n","Successfully installed opacus-0.15.0\n"]}]},{"cell_type":"code","metadata":{"id":"GS-jtN4Wsn2n","executionInfo":{"status":"ok","timestamp":1638735075190,"user_tz":420,"elapsed":997,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n","\n","SAMPLE_RATE = BATCH_SIZE / len(train_dataset)\n","\n","train_sampler=UniformWithReplacementSampler(\n","    num_samples=len(train_dataset),\n","    sample_rate=SAMPLE_RATE,\n",")\n","train_dataloader = DataLoader(train_dataset, batch_sampler=train_sampler)\n","\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z7npr7V4sn2n"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"OC6IzWeEsn2o","executionInfo":{"status":"ok","timestamp":1638735184880,"user_tz":420,"elapsed":107285,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["import torch\n","\n","# Move the model to appropriate device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Set the model to train mode (HuggingFace models load in eval mode)\n","model = model.train()\n","\n","# Define optimizer\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, eps=1e-8)\n","#lambda1 = lambda epoch: 0.65 ** epoch\n","#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda1)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcfEtHMasn2o"},"source":["First we specify some training parameters ready to run the training loop for three epochs"]},{"cell_type":"code","metadata":{"id":"JyZClL94sn2o","executionInfo":{"status":"ok","timestamp":1638735190309,"user_tz":420,"elapsed":257,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["EPOCHS = 3\n","LOGGING_INTERVAL = 100 # once every how many steps we run evaluation cycle and report metrics\n","EPSILON = 5.5\n","DELTA = 1 / len(train_dataloader) # Parameter for privacy accounting. Probability of not achieving privacy guarantees"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ya6AeJTzsn2o"},"source":["Let’s now define the evaluation cycle."]},{"cell_type":"code","metadata":{"id":"dFj73eZAsn2p","executionInfo":{"status":"ok","timestamp":1638735193866,"user_tz":420,"elapsed":12,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","from tqdm.notebook import tqdm\n","\n","def accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","# define evaluation cycle\n","def evaluate(model):    \n","    model.eval()\n","\n","    loss_arr = []\n","    pred_arr = []\n","    label_arr = []\n","    accuracy_arr = []\n","    \n","    for batch in test_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2],\n","                      'labels':         batch[3]}\n","\n","            outputs = model(**inputs)\n","            loss, logits = outputs[:2]\n","            loss = outputs[0]\n","            logits = torch.abs(outputs[1])\n","            preds = np.argmax(logits.detach().cpu().numpy(), axis=1)\n","            labels = inputs['labels'].detach().cpu().numpy()\n","            \n","            loss_arr.append(loss.item())\n","            accuracy_arr.append(accuracy(preds, labels))\n","\n","    model.train()\n","    \n","    return np.mean(loss_arr), np.mean(accuracy_arr)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lcn5IjJzsn2p"},"source":["Next we will define and attach PrivacyEngine. There are two parameters you need to consider here:\n","\n","- `noise_multiplier`. It defines the trade-off between privacy and accuracy. Adding more noise will provide stronger privacy guarantees, but will also hurt model quality.  In this run, the PrivacyEngine will determine this value based on the target values of `EPSILON`, `DELTA` and `EPOCHS`.  For the default settings, this will set `noise_multiplier` to about 0.4. \n","- `max_grad_norm`. Defines the maximum magnitude of L2 norms to which we clip per sample gradients. There is a bit of tug of war with this threshold: on the one hand, a low threshold means that we will clip many gradients, hurting convergence, so we might be tempted to raise it. However, recall that we add noise with `std=noise_multiplier * max_grad_norm` so we will pay for the increased threshold with more noise. In most cases you can rely on the model being quite resilient to clipping (after the first few iterations your model will tend to adjust so that its gradients stay below the clipping threshold), so you can often just keep the default value (`=1.0`) and focus on tuning `batch_size` and `noise_multiplier` instead. That being said, sometimes clipping hurts the model so it may be worth experimenting with different clipping thresholds, like we are doing in this tutorial.\n","\n","These two parameters define the scale of the noise we add to gradients: the noise will be sampled from a Gaussian distribution with `std=noise_multiplier * max_grad_norm`.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50Y6xU5Csn2p","executionInfo":{"status":"ok","timestamp":1638735197128,"user_tz":420,"elapsed":840,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"fdd83062-d14d-44b7-adc1-2e596baec57c"},"source":["from opacus import PrivacyEngine\n","\n","MAX_GRAD_NORM = 0.1\n","\n","privacy_engine = PrivacyEngine(\n","    module=model,\n","    sample_rate=SAMPLE_RATE * N_ACCUMULATION_STEPS,\n","    target_delta = DELTA,\n","    target_epsilon = EPSILON, \n","    epochs = EPOCHS,\n","    max_grad_norm=MAX_GRAD_NORM,\n",")\n","privacy_engine.attach(optimizer)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:760: UserWarning: A ``sample_rate`` has been provided.Thus, the provided ``batch_size``and ``sample_size`` will be ignored.\n","  \"A ``sample_rate`` has been provided.\"\n","/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:237: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n","  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"]}]},{"cell_type":"markdown","metadata":{"id":"IkdZegfIsn2q"},"source":["Now we can train the model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2747d4def4044b2ab7986aa6374323ec","2090cb5c8d8b4ee9932adb98c2b4b05e","b76d2e01514b461a87472249cf637b81","153dd19ba7cf4fe084baf5f96a254a16","72246a2ab738465ebf18555e1f3a70cb","078bb7ff6e7c475f869136b589f91e62","9a6f41073e6746d0808eaf3ea5f60779","4500279cf0d047aeac58fe3bfd6bffa9","73503cdc8bd84cb59a47004d7a716666","6c9af4e0531b42259b4b4f731bf76b8c","26057ae8de674b07b1ae23c697992c6c","1b4020bd80364dd99dd1bf5cd1a0e334","3b67c1a3bc2142609acaa6f5753c14fb","569ef315ba9b42b6903b0807c6b94cd1","02940e86a6414a3c9ae5df2d1a971d99","3f2ac57490fe4841a4a5bb514572da70","463b46e639a340fb891399d30f49eea2","df279523355147cc817b272e1a2475c7","0adb8f5ec45845cbaa695c547fedb92f","ab643e6a091f433dbf480f15042876b6","da628b5310ad40bfad41cc87a0dd3fff","502ada72250a4914934b22f23421aa52","662696c77e8349dc9f8019f28feed0a4","bca5dcec3cf64802b9e73eeeb9edd37f","91a310a37b164b54900590995eae75b3","6eaabe21ccaf4ff7bb92d63159253ebe","3567853897ca409397045a7b57cca4ed","75c44c2380884115ae1a03059438b32b","844ac4256a0849d0b1c8a60ca9f5cb5e","b1d31b798c3e4b78911d7a69de263c8a","459dae1962c64d989df87f3f310770a3","e3b8a37904e449429a094da4b8d592fc","7b0b8e812bd444959a8eceb0140428a8"]},"id":"RGdDvbAHsn2q","executionInfo":{"status":"ok","timestamp":1638736976878,"user_tz":420,"elapsed":1770011,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"48c80421-3156-485a-9ae6-ff410ee1db1b"},"source":["for epoch in range(1, EPOCHS+1):\n","\n","    torch.manual_seed(19)\n","    torch.cuda.manual_seed_all(19)\n","\n","    losses = []\n","    model.train()\n","\n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","        \n","        batch = tuple(t.to(device) for t in batch)\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'token_type_ids': batch[2],\n","                  'labels':         batch[3]}\n","\n","        outputs = model(**inputs) # output = loss, logits, hidden_states, attentions\n","\n","        loss = outputs[0]\n","        loss.backward()\n","        \n","        losses.append(loss.item())\n","\n","        # We process small batches of size BATCH_SIZE, \n","        # until they're accumulated to a batch of size VIRTUAL_BATCH_SIZE.\n","        # Only then we make a real `.step()` and update model weights\n","        if (step + 1) % N_ACCUMULATION_STEPS == 0 or step == len(train_dataloader) - 1:\n","            optimizer.step()\n","        else:\n","            optimizer.virtual_step()\n","\n","        if step > 0 and step % LOGGING_INTERVAL == 0:\n","            train_loss = np.mean(losses)\n","            eps, alpha = optimizer.privacy_engine.get_privacy_spent(DELTA)\n","\n","            eval_loss, eval_accuracy = evaluate(model)\n","\n","            print(\n","                f\"Epoch: {epoch} | \"\n","                f\"Step: {step} | \"\n","                f\"Train loss: {train_loss:.3f} | \"\n","                f\"Eval loss: {eval_loss:.3f} | \"\n","                f\"Eval accuracy: {eval_accuracy:.3f} | \"\n","                f\"ɛ: {eps:.2f} (α: {alpha})\"\n","            )"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2747d4def4044b2ab7986aa6374323ec","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3824 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | Step: 100 | Train loss: 0.885 | Eval loss: 1.565 | Eval accuracy: 0.828 | ɛ: 2.95 (α: 3.3)\n","Epoch: 1 | Step: 200 | Train loss: 1.289 | Eval loss: 1.728 | Eval accuracy: 0.828 | ɛ: 3.14 (α: 3.2)\n","Epoch: 1 | Step: 300 | Train loss: 1.508 | Eval loss: 1.346 | Eval accuracy: 0.828 | ɛ: 3.26 (α: 3.1)\n","Epoch: 1 | Step: 400 | Train loss: 1.437 | Eval loss: 1.199 | Eval accuracy: 0.828 | ɛ: 3.35 (α: 3.1)\n","Epoch: 1 | Step: 500 | Train loss: 1.421 | Eval loss: 1.323 | Eval accuracy: 0.828 | ɛ: 3.44 (α: 3.1)\n","Epoch: 1 | Step: 600 | Train loss: 1.417 | Eval loss: 1.272 | Eval accuracy: 0.828 | ɛ: 3.51 (α: 3.0)\n","Epoch: 1 | Step: 700 | Train loss: 1.410 | Eval loss: 1.227 | Eval accuracy: 0.828 | ɛ: 3.56 (α: 3.0)\n","Epoch: 1 | Step: 800 | Train loss: 1.392 | Eval loss: 1.285 | Eval accuracy: 0.828 | ɛ: 3.62 (α: 3.0)\n","Epoch: 1 | Step: 900 | Train loss: 1.382 | Eval loss: 1.322 | Eval accuracy: 0.828 | ɛ: 3.67 (α: 3.0)\n","Epoch: 1 | Step: 1000 | Train loss: 1.376 | Eval loss: 1.260 | Eval accuracy: 0.828 | ɛ: 3.73 (α: 3.0)\n","Epoch: 1 | Step: 1100 | Train loss: 1.368 | Eval loss: 1.268 | Eval accuracy: 0.828 | ɛ: 3.77 (α: 2.9)\n","Epoch: 1 | Step: 1200 | Train loss: 1.355 | Eval loss: 1.238 | Eval accuracy: 0.828 | ɛ: 3.81 (α: 2.9)\n","Epoch: 1 | Step: 1300 | Train loss: 1.357 | Eval loss: 1.295 | Eval accuracy: 0.828 | ɛ: 3.84 (α: 2.9)\n","Epoch: 1 | Step: 1400 | Train loss: 1.342 | Eval loss: 1.298 | Eval accuracy: 0.828 | ɛ: 3.88 (α: 2.9)\n","Epoch: 1 | Step: 1500 | Train loss: 1.362 | Eval loss: 1.219 | Eval accuracy: 0.828 | ɛ: 3.92 (α: 2.9)\n","Epoch: 1 | Step: 1600 | Train loss: 1.369 | Eval loss: 1.235 | Eval accuracy: 0.828 | ɛ: 3.96 (α: 2.9)\n","Epoch: 1 | Step: 1700 | Train loss: 1.357 | Eval loss: 1.293 | Eval accuracy: 0.828 | ɛ: 3.99 (α: 2.9)\n","Epoch: 1 | Step: 1800 | Train loss: 1.363 | Eval loss: 1.273 | Eval accuracy: 0.828 | ɛ: 4.03 (α: 2.9)\n","Epoch: 1 | Step: 1900 | Train loss: 1.378 | Eval loss: 1.232 | Eval accuracy: 0.828 | ɛ: 4.07 (α: 2.8)\n","Epoch: 1 | Step: 2000 | Train loss: 1.378 | Eval loss: 1.273 | Eval accuracy: 0.828 | ɛ: 4.10 (α: 2.8)\n","Epoch: 1 | Step: 2100 | Train loss: 1.368 | Eval loss: 1.304 | Eval accuracy: 0.827 | ɛ: 4.12 (α: 2.8)\n","Epoch: 1 | Step: 2200 | Train loss: 1.377 | Eval loss: 1.229 | Eval accuracy: 0.827 | ɛ: 4.15 (α: 2.8)\n","Epoch: 1 | Step: 2300 | Train loss: 1.375 | Eval loss: 1.275 | Eval accuracy: 0.828 | ɛ: 4.17 (α: 2.8)\n","Epoch: 1 | Step: 2400 | Train loss: 1.379 | Eval loss: 1.277 | Eval accuracy: 0.827 | ɛ: 4.20 (α: 2.8)\n","Epoch: 1 | Step: 2500 | Train loss: 1.377 | Eval loss: 1.278 | Eval accuracy: 0.827 | ɛ: 4.23 (α: 2.8)\n","Epoch: 1 | Step: 2600 | Train loss: 1.386 | Eval loss: 1.246 | Eval accuracy: 0.828 | ɛ: 4.25 (α: 2.8)\n","Epoch: 1 | Step: 2700 | Train loss: 1.387 | Eval loss: 1.222 | Eval accuracy: 0.828 | ɛ: 4.28 (α: 2.8)\n","Epoch: 1 | Step: 2800 | Train loss: 1.378 | Eval loss: 1.347 | Eval accuracy: 0.828 | ɛ: 4.31 (α: 2.8)\n","Epoch: 1 | Step: 2900 | Train loss: 1.385 | Eval loss: 1.235 | Eval accuracy: 0.828 | ɛ: 4.33 (α: 2.8)\n","Epoch: 1 | Step: 3000 | Train loss: 1.388 | Eval loss: 1.241 | Eval accuracy: 0.828 | ɛ: 4.36 (α: 2.8)\n","Epoch: 1 | Step: 3100 | Train loss: 1.393 | Eval loss: 1.251 | Eval accuracy: 0.828 | ɛ: 4.39 (α: 2.8)\n","Epoch: 1 | Step: 3200 | Train loss: 1.392 | Eval loss: 1.258 | Eval accuracy: 0.827 | ɛ: 4.41 (α: 2.8)\n","Epoch: 1 | Step: 3300 | Train loss: 1.388 | Eval loss: 1.324 | Eval accuracy: 0.826 | ɛ: 4.44 (α: 2.8)\n","Epoch: 1 | Step: 3400 | Train loss: 1.383 | Eval loss: 1.247 | Eval accuracy: 0.824 | ɛ: 4.47 (α: 2.7)\n","Epoch: 1 | Step: 3500 | Train loss: 1.380 | Eval loss: 1.296 | Eval accuracy: 0.816 | ɛ: 4.48 (α: 2.7)\n","Epoch: 1 | Step: 3600 | Train loss: 1.376 | Eval loss: 1.299 | Eval accuracy: 0.816 | ɛ: 4.50 (α: 2.7)\n","Epoch: 1 | Step: 3700 | Train loss: 1.375 | Eval loss: 1.243 | Eval accuracy: 0.803 | ɛ: 4.52 (α: 2.7)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b4020bd80364dd99dd1bf5cd1a0e334","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3824 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2 | Step: 100 | Train loss: 1.189 | Eval loss: 1.298 | Eval accuracy: 0.709 | ɛ: 4.55 (α: 2.7)\n","Epoch: 2 | Step: 200 | Train loss: 1.241 | Eval loss: 1.316 | Eval accuracy: 0.641 | ɛ: 4.57 (α: 2.7)\n","Epoch: 2 | Step: 300 | Train loss: 1.364 | Eval loss: 1.236 | Eval accuracy: 0.660 | ɛ: 4.59 (α: 2.7)\n","Epoch: 2 | Step: 400 | Train loss: 1.338 | Eval loss: 1.270 | Eval accuracy: 0.719 | ɛ: 4.61 (α: 2.7)\n","Epoch: 2 | Step: 500 | Train loss: 1.346 | Eval loss: 1.311 | Eval accuracy: 0.661 | ɛ: 4.63 (α: 2.7)\n","Epoch: 2 | Step: 600 | Train loss: 1.350 | Eval loss: 1.252 | Eval accuracy: 0.690 | ɛ: 4.65 (α: 2.7)\n","Epoch: 2 | Step: 700 | Train loss: 1.359 | Eval loss: 1.264 | Eval accuracy: 0.714 | ɛ: 4.67 (α: 2.7)\n","Epoch: 2 | Step: 800 | Train loss: 1.349 | Eval loss: 1.308 | Eval accuracy: 0.648 | ɛ: 4.69 (α: 2.7)\n","Epoch: 2 | Step: 900 | Train loss: 1.346 | Eval loss: 1.331 | Eval accuracy: 0.557 | ɛ: 4.71 (α: 2.7)\n","Epoch: 2 | Step: 1000 | Train loss: 1.348 | Eval loss: 1.280 | Eval accuracy: 0.359 | ɛ: 4.73 (α: 2.7)\n","Epoch: 2 | Step: 1100 | Train loss: 1.346 | Eval loss: 1.311 | Eval accuracy: 0.288 | ɛ: 4.75 (α: 2.7)\n","Epoch: 2 | Step: 1200 | Train loss: 1.335 | Eval loss: 1.241 | Eval accuracy: 0.316 | ɛ: 4.77 (α: 2.7)\n","Epoch: 2 | Step: 1300 | Train loss: 1.341 | Eval loss: 1.335 | Eval accuracy: 0.213 | ɛ: 4.78 (α: 2.7)\n","Epoch: 2 | Step: 1400 | Train loss: 1.328 | Eval loss: 1.288 | Eval accuracy: 0.204 | ɛ: 4.81 (α: 2.7)\n","Epoch: 2 | Step: 1500 | Train loss: 1.351 | Eval loss: 1.224 | Eval accuracy: 0.220 | ɛ: 4.82 (α: 2.7)\n","Epoch: 2 | Step: 1600 | Train loss: 1.363 | Eval loss: 1.277 | Eval accuracy: 0.213 | ɛ: 4.84 (α: 2.7)\n","Epoch: 2 | Step: 1700 | Train loss: 1.353 | Eval loss: 1.312 | Eval accuracy: 0.228 | ɛ: 4.86 (α: 2.7)\n","Epoch: 2 | Step: 1800 | Train loss: 1.360 | Eval loss: 1.276 | Eval accuracy: 0.254 | ɛ: 4.88 (α: 2.7)\n","Epoch: 2 | Step: 1900 | Train loss: 1.377 | Eval loss: 1.244 | Eval accuracy: 0.266 | ɛ: 4.90 (α: 2.7)\n","Epoch: 2 | Step: 2000 | Train loss: 1.378 | Eval loss: 1.282 | Eval accuracy: 0.196 | ɛ: 4.92 (α: 2.7)\n","Epoch: 2 | Step: 2100 | Train loss: 1.372 | Eval loss: 1.338 | Eval accuracy: 0.173 | ɛ: 4.94 (α: 2.7)\n","Epoch: 2 | Step: 2200 | Train loss: 1.382 | Eval loss: 1.230 | Eval accuracy: 0.176 | ɛ: 4.96 (α: 2.6)\n","Epoch: 2 | Step: 2300 | Train loss: 1.380 | Eval loss: 1.295 | Eval accuracy: 0.187 | ɛ: 4.97 (α: 2.6)\n","Epoch: 2 | Step: 2400 | Train loss: 1.385 | Eval loss: 1.315 | Eval accuracy: 0.171 | ɛ: 4.99 (α: 2.6)\n","Epoch: 2 | Step: 2500 | Train loss: 1.385 | Eval loss: 1.297 | Eval accuracy: 0.167 | ɛ: 5.00 (α: 2.6)\n","Epoch: 2 | Step: 2600 | Train loss: 1.392 | Eval loss: 1.267 | Eval accuracy: 0.175 | ɛ: 5.02 (α: 2.6)\n","Epoch: 2 | Step: 2700 | Train loss: 1.395 | Eval loss: 1.257 | Eval accuracy: 0.193 | ɛ: 5.03 (α: 2.6)\n","Epoch: 2 | Step: 2800 | Train loss: 1.385 | Eval loss: 1.366 | Eval accuracy: 0.207 | ɛ: 5.05 (α: 2.6)\n","Epoch: 2 | Step: 2900 | Train loss: 1.392 | Eval loss: 1.259 | Eval accuracy: 0.236 | ɛ: 5.06 (α: 2.6)\n","Epoch: 2 | Step: 3000 | Train loss: 1.397 | Eval loss: 1.274 | Eval accuracy: 0.248 | ɛ: 5.08 (α: 2.6)\n","Epoch: 2 | Step: 3100 | Train loss: 1.403 | Eval loss: 1.260 | Eval accuracy: 0.257 | ɛ: 5.09 (α: 2.6)\n","Epoch: 2 | Step: 3200 | Train loss: 1.405 | Eval loss: 1.319 | Eval accuracy: 0.270 | ɛ: 5.11 (α: 2.6)\n","Epoch: 2 | Step: 3300 | Train loss: 1.401 | Eval loss: 1.368 | Eval accuracy: 0.206 | ɛ: 5.12 (α: 2.6)\n","Epoch: 2 | Step: 3400 | Train loss: 1.397 | Eval loss: 1.307 | Eval accuracy: 0.181 | ɛ: 5.14 (α: 2.6)\n","Epoch: 2 | Step: 3500 | Train loss: 1.395 | Eval loss: 1.361 | Eval accuracy: 0.164 | ɛ: 5.15 (α: 2.6)\n","Epoch: 2 | Step: 3600 | Train loss: 1.392 | Eval loss: 1.368 | Eval accuracy: 0.165 | ɛ: 5.17 (α: 2.6)\n","Epoch: 2 | Step: 3700 | Train loss: 1.391 | Eval loss: 1.310 | Eval accuracy: 0.163 | ɛ: 5.18 (α: 2.6)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"662696c77e8349dc9f8019f28feed0a4","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3824 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3 | Step: 100 | Train loss: 1.223 | Eval loss: 1.401 | Eval accuracy: 0.168 | ɛ: 5.20 (α: 2.6)\n","Epoch: 3 | Step: 200 | Train loss: 1.293 | Eval loss: 1.383 | Eval accuracy: 0.171 | ɛ: 5.22 (α: 2.6)\n","Epoch: 3 | Step: 300 | Train loss: 1.404 | Eval loss: 1.287 | Eval accuracy: 0.170 | ɛ: 5.23 (α: 2.6)\n","Epoch: 3 | Step: 400 | Train loss: 1.368 | Eval loss: 1.322 | Eval accuracy: 0.168 | ɛ: 5.25 (α: 2.6)\n","Epoch: 3 | Step: 500 | Train loss: 1.379 | Eval loss: 1.381 | Eval accuracy: 0.165 | ɛ: 5.26 (α: 2.6)\n","Epoch: 3 | Step: 600 | Train loss: 1.384 | Eval loss: 1.331 | Eval accuracy: 0.162 | ɛ: 5.28 (α: 2.6)\n","Epoch: 3 | Step: 700 | Train loss: 1.399 | Eval loss: 1.304 | Eval accuracy: 0.160 | ɛ: 5.29 (α: 2.6)\n","Epoch: 3 | Step: 800 | Train loss: 1.384 | Eval loss: 1.352 | Eval accuracy: 0.158 | ɛ: 5.31 (α: 2.6)\n","Epoch: 3 | Step: 900 | Train loss: 1.381 | Eval loss: 1.381 | Eval accuracy: 0.158 | ɛ: 5.32 (α: 2.6)\n","Epoch: 3 | Step: 1000 | Train loss: 1.384 | Eval loss: 1.312 | Eval accuracy: 0.160 | ɛ: 5.34 (α: 2.6)\n","Epoch: 3 | Step: 1100 | Train loss: 1.382 | Eval loss: 1.349 | Eval accuracy: 0.159 | ɛ: 5.35 (α: 2.6)\n","Epoch: 3 | Step: 1200 | Train loss: 1.368 | Eval loss: 1.289 | Eval accuracy: 0.171 | ɛ: 5.37 (α: 2.6)\n","Epoch: 3 | Step: 1300 | Train loss: 1.380 | Eval loss: 1.384 | Eval accuracy: 0.167 | ɛ: 5.38 (α: 2.6)\n","Epoch: 3 | Step: 1400 | Train loss: 1.366 | Eval loss: 1.323 | Eval accuracy: 0.168 | ɛ: 5.40 (α: 2.6)\n","Epoch: 3 | Step: 1500 | Train loss: 1.394 | Eval loss: 1.266 | Eval accuracy: 0.171 | ɛ: 5.41 (α: 2.6)\n","Epoch: 3 | Step: 1600 | Train loss: 1.407 | Eval loss: 1.322 | Eval accuracy: 0.173 | ɛ: 5.43 (α: 2.6)\n","Epoch: 3 | Step: 1700 | Train loss: 1.397 | Eval loss: 1.394 | Eval accuracy: 0.177 | ɛ: 5.44 (α: 2.6)\n","Epoch: 3 | Step: 1800 | Train loss: 1.403 | Eval loss: 1.356 | Eval accuracy: 0.187 | ɛ: 5.46 (α: 2.6)\n","Epoch: 3 | Step: 1900 | Train loss: 1.421 | Eval loss: 1.304 | Eval accuracy: 0.198 | ɛ: 5.47 (α: 2.6)\n","Epoch: 3 | Step: 2000 | Train loss: 1.422 | Eval loss: 1.350 | Eval accuracy: 0.188 | ɛ: 5.49 (α: 2.6)\n","Epoch: 3 | Step: 2100 | Train loss: 1.417 | Eval loss: 1.409 | Eval accuracy: 0.197 | ɛ: 5.50 (α: 2.6)\n","Epoch: 3 | Step: 2200 | Train loss: 1.427 | Eval loss: 1.306 | Eval accuracy: 0.211 | ɛ: 5.51 (α: 2.6)\n","Epoch: 3 | Step: 2300 | Train loss: 1.423 | Eval loss: 1.341 | Eval accuracy: 0.219 | ɛ: 5.53 (α: 2.6)\n","Epoch: 3 | Step: 2400 | Train loss: 1.428 | Eval loss: 1.408 | Eval accuracy: 0.213 | ɛ: 5.54 (α: 2.5)\n","Epoch: 3 | Step: 2500 | Train loss: 1.428 | Eval loss: 1.370 | Eval accuracy: 0.209 | ɛ: 5.56 (α: 2.5)\n","Epoch: 3 | Step: 2600 | Train loss: 1.433 | Eval loss: 1.306 | Eval accuracy: 0.220 | ɛ: 5.57 (α: 2.5)\n","Epoch: 3 | Step: 2700 | Train loss: 1.436 | Eval loss: 1.330 | Eval accuracy: 0.250 | ɛ: 5.58 (α: 2.5)\n","Epoch: 3 | Step: 2800 | Train loss: 1.425 | Eval loss: 1.445 | Eval accuracy: 0.272 | ɛ: 5.59 (α: 2.5)\n","Epoch: 3 | Step: 2900 | Train loss: 1.432 | Eval loss: 1.350 | Eval accuracy: 0.293 | ɛ: 5.60 (α: 2.5)\n","Epoch: 3 | Step: 3000 | Train loss: 1.438 | Eval loss: 1.290 | Eval accuracy: 0.302 | ɛ: 5.61 (α: 2.5)\n","Epoch: 3 | Step: 3100 | Train loss: 1.442 | Eval loss: 1.307 | Eval accuracy: 0.307 | ɛ: 5.63 (α: 2.5)\n","Epoch: 3 | Step: 3200 | Train loss: 1.445 | Eval loss: 1.398 | Eval accuracy: 0.314 | ɛ: 5.64 (α: 2.5)\n","Epoch: 3 | Step: 3300 | Train loss: 1.439 | Eval loss: 1.421 | Eval accuracy: 0.279 | ɛ: 5.65 (α: 2.5)\n","Epoch: 3 | Step: 3400 | Train loss: 1.436 | Eval loss: 1.389 | Eval accuracy: 0.255 | ɛ: 5.66 (α: 2.5)\n","Epoch: 3 | Step: 3500 | Train loss: 1.434 | Eval loss: 1.458 | Eval accuracy: 0.233 | ɛ: 5.67 (α: 2.5)\n","Epoch: 3 | Step: 3600 | Train loss: 1.432 | Eval loss: 1.449 | Eval accuracy: 0.226 | ɛ: 5.69 (α: 2.5)\n","Epoch: 3 | Step: 3700 | Train loss: 1.432 | Eval loss: 1.408 | Eval accuracy: 0.211 | ɛ: 5.70 (α: 2.5)\n"]}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":77},"id":"S222a-xROude","executionInfo":{"status":"ok","timestamp":1638737044579,"user_tz":420,"elapsed":39152,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"4befe47c-9bd8-4aea-ca38-6761d3b44635"},"source":["from google.colab import files\n","PS_file = files.upload()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-f6cd2dce-820a-4bd3-8da1-da5f7424c1cc\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f6cd2dce-820a-4bd3-8da1-da5f7424c1cc\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving prediction_score.csv to prediction_score.csv\n"]}]},{"cell_type":"code","metadata":{"id":"4K2d3jlzPCNr","executionInfo":{"status":"ok","timestamp":1638737046929,"user_tz":420,"elapsed":173,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["ps_data = pd.read_csv('/content/prediction_score.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"B8fafNRPPgXF","executionInfo":{"status":"ok","timestamp":1638737083016,"user_tz":420,"elapsed":179,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"6de965dd-2ca1-4c6b-cec1-962e21ea2fc8"},"source":["ps_data"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweet</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Corona time gains We have no control over the ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>This is how Chinese people caught Corona Virus...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>an empty Escalator at M Purple Line station. W...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I am working away from home to earn a living a...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The virus is too dangerous and may last for ma...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Tweet  target\n","0  Corona time gains We have no control over the ...       0\n","1  This is how Chinese people caught Corona Virus...       0\n","2  an empty Escalator at M Purple Line station. W...       0\n","3  I am working away from home to earn a living a...       0\n","4  The virus is too dangerous and may last for ma...       0"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voeLWLAKPPcB","executionInfo":{"status":"ok","timestamp":1638737084518,"user_tz":420,"elapsed":5,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"6786ec84-012d-4bca-bd18-63faffad2db8"},"source":["ps_features = _df_to_features(ps_data, \"test\")\n","ps_dataset = _features_to_dataset(ps_features)\n","ps_sampler = SequentialSampler(ps_dataset)\n","ps_dataloader = DataLoader(ps_dataset, sampler=ps_sampler, batch_size=5)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"]}]},{"cell_type":"code","metadata":{"id":"NgDh463TPWU1","executionInfo":{"status":"ok","timestamp":1638737086096,"user_tz":420,"elapsed":2,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}}},"source":["for batch in ps_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2],\n","                      'labels':         batch[3]}"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0O7eJIPBPZG-","executionInfo":{"status":"ok","timestamp":1638737087757,"user_tz":420,"elapsed":225,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"33bc78c0-443a-4688-ca28-b88ae847dfd1"},"source":["outputs = model(**inputs)\n","loss, logits = outputs[:2]\n","loss = outputs[0]\n","logits = torch.abs(outputs[1])\n","preds = np.argmax(logits.detach().cpu().numpy(), axis=1)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_QbTUKOPcXm","executionInfo":{"status":"ok","timestamp":1638737089331,"user_tz":420,"elapsed":164,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"dedbb53b-ee2e-4377-fd61-e1cfaa652a6a"},"source":["logits"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5.3435, 3.7709],\n","        [5.6878, 2.3265],\n","        [5.1261, 3.2730],\n","        [4.4799, 3.5603],\n","        [4.5701, 2.1722]], device='cuda:0', grad_fn=<AbsBackward0>)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdkdmTZKPE80","executionInfo":{"status":"ok","timestamp":1638737112074,"user_tz":420,"elapsed":180,"user":{"displayName":"Sohyun Park","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyT5oxIj5_uMFxofSZfOeHW6kK8z91sUr_yrZI=s64","userId":"04447429537998349604"}},"outputId":"774386cd-9994-4eb4-aaad-f902565eb784"},"source":["preds"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unTxptXV8TEn","outputId":"c227a270-e142-400c-8fbe-6345724b3c0f"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Nov 10 09:03:01 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    40W / 250W |  13595MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"jk32axB1sn2r"},"source":["For the test accuracy, after training for three epochs you should expect something close to the results below.\n","\n","You can see that we can achieve quite strong privacy guarantee at epsilon=7.5 with a moderate accuracy cost of 11 percentage points compared to non-private model trained in a similar setting (upper layers only) and 16 points compared to best results we were able to achieve using the same architecture.\n","\n","*NB: When not specified, DP-SGD is trained with upper layers only*"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"NWRwaBQ0sn2r"},"source":["| Model | Noise multiplier | Batch size | Accuracy | Epsilon |\n","| --- | --- | --- | --- | --- |\n","| no DP, train full model | N/A | 32 | 90.1% | N/A |\n","| no DP, train upper layers only | N/A | 32 | 85.4% | N/A |\n","| DP-SGD | 1.0 | 32 | 70.5% | 0.7 |\n","| **DP-SGD (this tutorial)** | **0.4** | **32** | **74.3%** | **7.5** |\n","| DP-SGD | 0.3 | 32 | 75.8% | 20.7 |\n","| DP-SGD | 0.1 | 32 | 78.3% | 2865 |\n","| DP-SGD | 0.4 | 8 | 67.3% | 5.9 |"]}]}